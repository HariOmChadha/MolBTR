{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pretrain using the Barlow Twin method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from Modules.molclr import main\n",
    "from Modules.finetune import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the config file to set the hyperparameters\n",
    "config = yaml.load(open(\"config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "print(config)\n",
    "\n",
    "main(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finetune the model by loading in the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the finetune config_finetune file to change the rest of the hyperparameters\n",
    "# changes are made to the config file based on the infomation below. \n",
    "\n",
    "# lists used to automate the process of finetuning multiple models\n",
    "task = ['visc']   # 'cond', 'visc', 'visc_hc'\n",
    "tune_from = ['BT14']  # BT1: 15% subgraph, BT2: 15% subgraph, 20% node/edge\n",
    "runs = [10]     # number of tests to run with the same hyperparameters\n",
    "targets = [7]      # number of train set size splits to use (max is 7) - 0.1, 0.2, 0.3...0.7\n",
    "main_folder = ['results_visc_subgraph_3']  # folder to save the results\n",
    "\n",
    "for i in range(len(main_folder)):\n",
    "    run(task[i], f\"finetune/{main_folder[i]}\", tune_from[i], runs[i], targets[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
